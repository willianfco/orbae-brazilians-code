{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,torchvision,PIL,sklearn,matplotlib,wandb,captum --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the environment\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.set_seed import set_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.data_utils import prepare_dataset\n",
    "from utils.model_eval import predict, visualize_integrated_gradients_age\n",
    "from warnings import filterwarnings\n",
    "\n",
    "# Filter Warnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "\n",
    "SEED = 0\n",
    "set_seed(SEED)\n",
    "\n",
    "# Get start time of the current experiment\n",
    "start_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n",
    "\n",
    "# Set the device to GPU if available\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(DEVICE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from csv file\n",
    "\n",
    "df = pd.read_csv(\"Data\\ccs_dataset.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation and test sets according to the model training split strategy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df.age_group)\n",
    "test_df, val_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df.age_group)\n",
    "\n",
    "# Deleting unecessary sets to free memory\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if ids on train and test sets are disjoint\n",
    "\n",
    "train_ids = set(train_df.id)\n",
    "test_ids = set(test_df.id)\n",
    "print(f\"Train and test ids are disjoint: {len(train_ids.intersection(test_ids)) == 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the test set\n",
    "\n",
    "print(f\"Holdout set shape: {test_df.shape}\")\n",
    "test_df.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the test set\n",
    "\n",
    "test_dataset = prepare_dataset(\n",
    "    test_df,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    augment=False,\n",
    "    multitask=False,\n",
    "    input_size=(299, 299),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the validation set\n",
    "\n",
    "val_dataset = prepare_dataset(\n",
    "    val_df,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    augment=False,\n",
    "    multitask=False,\n",
    "    input_size=(299, 299),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model and loading the best weights\n",
    "\n",
    "from torch import nn\n",
    "from models.pytorch.architectures.InceptionV4 import (\n",
    "    InceptionStem,\n",
    "    InceptionA,\n",
    "    InceptionB,\n",
    "    InceptionC,\n",
    "    ReductionA,\n",
    "    ReductionB,\n",
    ")\n",
    "\n",
    "\n",
    "class InceptionV4(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_prob, dense_units):\n",
    "        super(InceptionV4, self).__init__()\n",
    "\n",
    "        self.stem = InceptionStem()\n",
    "\n",
    "        self.inception_a_blocks = nn.Sequential(\n",
    "            InceptionA(384),\n",
    "            InceptionA(384),\n",
    "            InceptionA(384),\n",
    "            InceptionA(384),\n",
    "        )\n",
    "\n",
    "        self.reduction_a = ReductionA(384)\n",
    "\n",
    "        self.inception_b_blocks = nn.Sequential(\n",
    "            InceptionB(1024),\n",
    "            InceptionB(1024),\n",
    "            InceptionB(1024),\n",
    "            InceptionB(1024),\n",
    "            InceptionB(1024),\n",
    "            InceptionB(1024),\n",
    "            InceptionB(1024),\n",
    "        )\n",
    "\n",
    "        self.reduction_b = ReductionB(1024)\n",
    "\n",
    "        self.inception_c_blocks = nn.Sequential(\n",
    "            InceptionC(1536),\n",
    "            InceptionC(1536),\n",
    "            InceptionC(1536),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc1 = nn.Linear(1536, dense_units)\n",
    "        self.fc2 = nn.Linear(dense_units, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception_a_blocks(x)\n",
    "        x = self.reduction_a(x)\n",
    "        x = self.inception_b_blocks(x)\n",
    "        x = self.reduction_b(x)\n",
    "        x = self.inception_c_blocks(x)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Creating the model: InceptionV4\n",
    "model = InceptionV4(\n",
    "    num_classes=1, # 1 for age regression, 2 for sexual dimorfism classification\n",
    "    dropout_prob=0.7,\n",
    "    dense_units=1024,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Loading the model best_weights\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"models/pytorch/weights/your_model_best_weights.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set\n",
    "\n",
    "test_df[\"pred\"] = predict(model, test_dataset, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the validation set\n",
    "\n",
    "val_df[\"pred\"] = predict(model, val_dataset, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test adversarial perturbations \n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def test(model, device, data_loader, epsilon):\n",
    "    perturbed_total_loss = 0\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for data, target in data_loader:\n",
    "        data, target = data.to(device).float(), target.to(device).float()\n",
    "        target = target.view(-1, 1)  # Transforming target to the same shape as the output\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        perturbed_output = model(perturbed_data)\n",
    "        perturbed_loss = loss_fn(perturbed_output, target)\n",
    "        perturbed_total_loss += perturbed_loss.item() * len(target)\n",
    "\n",
    "    avg_perturbed_loss = perturbed_total_loss / len(data_loader.dataset)\n",
    "    print(\"Epsilon: {}\\tPerturbed Average Loss = {}\".format(epsilon, avg_perturbed_loss))\n",
    "\n",
    "    return avg_perturbed_loss\n",
    "\n",
    "\n",
    "perturbed_avg_losses = []\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    perturbed_avg_loss = test(model, DEVICE, test_dataset, eps)\n",
    "    perturbed_avg_losses.append(perturbed_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with the results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame({\n",
    "    'Epsilon': epsilons,\n",
    "    'Perturbed Average Loss': perturbed_avg_losses\n",
    "})\n",
    "\n",
    "# Setting the style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Creating the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=results_df, x='Epsilon', y='Perturbed Average Loss', marker='o', color='blue')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Effect of FGSM Attack on the Model', fontsize=14)\n",
    "plt.xlabel('Epsilon', fontsize=12)\n",
    "plt.ylabel('Perturbed MSE Loss', fontsize=12)\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the absolute error between the real age and the predicted age\n",
    "\n",
    "test_df[\"error\"] = test_df[\"age_in_years\"] - test_df[\"pred\"]\n",
    "test_df[\"abs_error\"] = abs(test_df[\"age_in_years\"] - test_df[\"pred\"])\n",
    "\n",
    "# Visualizing the test set with the predictions\n",
    "test_df.head().style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the absolute error between the real age and the predicted age\n",
    "\n",
    "val_df[\"error\"] = val_df[\"age_in_years\"] - val_df[\"pred\"]\n",
    "val_df[\"abs_error\"] = abs(val_df[\"age_in_years\"] - val_df[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the absolute error per age group\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "age_groups = test_df[\"age_group\"].unique()\n",
    "min_age_per_group = {group: test_df[test_df[\"age_group\"] == group][\"age_in_years\"].min() for group in age_groups}\n",
    "age_groups_sorted = sorted(age_groups, key=lambda group: min_age_per_group[group])\n",
    "\n",
    "ax = sns.barplot(\n",
    "    x=\"age_group\",\n",
    "    y=\"abs_error\",\n",
    "    data=test_df,\n",
    "    order=age_groups_sorted,\n",
    "    color=\"seagreen\",\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "ax.set(xlabel=\"Age Group\")\n",
    "ax.set(ylabel=\"Holdout MAE (years)\")\n",
    "plt.title(\"Mean Absolute Error per Age Group in Age Prediction with InceptionV4\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation MAE and IC for the Validation Set\n",
    "\n",
    "mae_val = val_df[\"abs_error\"].mean()\n",
    "icse_val = 1.96 * val_df[\"abs_error\"].std() / np.sqrt(val_df.shape[0])\n",
    "\n",
    "print(f\"Validation MAE: {mae_val:.3f} ± {icse_val:.3f} years\")\n",
    "\n",
    "# Calculation MSE and IC for the Validation Set\n",
    "\n",
    "mse_val = (val_df[\"error\"] ** 2).mean()\n",
    "icse_val = 1.96 * val_df[\"error\"].std() / np.sqrt(val_df.shape[0])\n",
    "\n",
    "print(f\"Validation MSE: {mse_val:.3f} ± {icse_val:.3f} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating MAE and IC for the test set\n",
    "mae = test_df[\"abs_error\"].mean()\n",
    "ic = 1.96 * test_df[\"abs_error\"].std() / np.sqrt(len(test_df)) # 95% confidence interval\n",
    "\n",
    "print(f\"MAE: {mae:.3f} ± {ic:.3f} years\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating MSE and IC for the test set\n",
    "\n",
    "mse = (test_df[\"error\"] ** 2).mean()\n",
    "ic = 1.96 * test_df[\"error\"].std() / np.sqrt(len(test_df)) # 95% confidence interval\n",
    "\n",
    "print(f\"MSE: {mse:.3f} ± {ic:.3f} years²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating MAE and robust measures of spread for the test set\n",
    "mae = test_df[\"abs_error\"].mean()\n",
    "mse = test_df[\"abs_error\"].pow(2).mean()\n",
    "median_abs_error = test_df[\"abs_error\"].median()\n",
    "q1, q3 = test_df[\"abs_error\"].quantile([0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "\n",
    "print(f\"MAE: {mae:.3f} years\")\n",
    "print(f\"Mean Squared Error: {mse:.3f} years\")\n",
    "print(f\"Median absolute error: {median_abs_error:.3f} years\")\n",
    "print(f\"25th percentile of absolute error: {q1:.3f} years\")\n",
    "print(f\"75th percentile of absolute error: {q3:.3f} years\")\n",
    "print(f\"IQR of absolute error: {iqr:.3f} years\")\n",
    "\n",
    "# Calculating R² and Explained Variance for the test set\n",
    "\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "\n",
    "r2 = r2_score(test_df[\"age_in_years\"], test_df[\"pred\"])\n",
    "ev = explained_variance_score(test_df[\"age_in_years\"], test_df[\"pred\"])\n",
    "\n",
    "print(f\"R²: {r2:.3f}\")\n",
    "print(f\"Explained Variance: {ev:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Round ages to nearest integer\n",
    "test_df['rounded_age'] = test_df['age_in_years'].round()\n",
    "\n",
    "# Define a function to calculate the bootstrap confidence interval\n",
    "def bootstrap_ci(data, n_iterations=1000, ci=95):\n",
    "    stats = list()\n",
    "    for _ in range(n_iterations):\n",
    "        sample = resample(data)\n",
    "        stats.append(sample.mean())\n",
    "    return (\n",
    "        np.percentile(stats, (100 - ci) / 2),\n",
    "        np.percentile(stats, ci + (100 - ci) / 2),\n",
    "    )\n",
    "\n",
    "# Group by rounded_age and calculate mean error and bootstrap confidence interval for each age\n",
    "grouped = test_df.groupby(\"rounded_age\").agg(\n",
    "    {\"abs_error\": [\"mean\", lambda x: bootstrap_ci(x)]}\n",
    ")\n",
    "grouped.columns = [\"MeanError\", \"ConfInterval\"]\n",
    "\n",
    "# Separate the lower and upper bounds of the confidence interval into separate columns\n",
    "grouped[[\"LowerCI\", \"UpperCI\"]] = pd.DataFrame(\n",
    "    grouped[\"ConfInterval\"].tolist(), index=grouped.index\n",
    ")\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Set Seaborn color palette\n",
    "sns.set_palette(\"crest\")\n",
    "\n",
    "# Plot the mean error as a line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    grouped.index,\n",
    "    grouped[\"MeanError\"],\n",
    "    label=\"Mean Error\",\n",
    ")\n",
    "\n",
    "# Plot the confidence interval as a shaded area\n",
    "plt.fill_between(\n",
    "    grouped.index,\n",
    "    grouped[\"LowerCI\"],\n",
    "    grouped[\"UpperCI\"],\n",
    "    color=sns.color_palette(\"crest\")[2],\n",
    "    alpha=0.2,\n",
    "    label=\"95% Confidence Interval\",\n",
    ")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Age in Years\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.title(\"Mean Absolute Error and Confidence Interval by Age\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# Display the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin ages into 5-year intervals\n",
    "bins = np.arange(0, test_df[\"age_in_years\"].max() + 5, 5)\n",
    "test_df[\"binned_age\"] = pd.cut(test_df[\"age_in_years\"], bins, right=False)\n",
    "\n",
    "# Group by binned_age and calculate mean and confidence interval for each age group\n",
    "grouped = test_df.groupby(\"binned_age\").agg({\"abs_error\": [\"mean\", \"std\", \"count\"]})\n",
    "grouped.columns = [\"MeanError\", \"StdError\", \"Count\"]\n",
    "grouped[\"ConfInterval\"] = (\n",
    "    1.96 * grouped[\"StdError\"] / np.sqrt(grouped[\"Count\"])\n",
    ")  # 95% confidence interval\n",
    "\n",
    "# Compute mid-points of intervals for plotting\n",
    "grouped[\"MidPoint\"] = grouped.index.map(lambda x: x.mid)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the mean error as a line using Seaborn\n",
    "sns.lineplot(x=grouped[\"MidPoint\"], y=grouped[\"MeanError\"], label=\"Mean Error\")\n",
    "\n",
    "# Plot the confidence interval as a shaded area using Matplotlib\n",
    "plt.fill_between(\n",
    "    grouped[\"MidPoint\"],\n",
    "    (grouped[\"MeanError\"] - grouped[\"ConfInterval\"]),\n",
    "    (grouped[\"MeanError\"] + grouped[\"ConfInterval\"]),\n",
    "    color=sns.color_palette(\"crest\")[2],\n",
    "    alpha=0.1,\n",
    "    label=\"95% Confidence Interval\",\n",
    ")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Age in Years\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.title(\"Mean Absolute Error and Confidence Interval by Age\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# Remove the top and right spines from plot\n",
    "sns.despine()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average and difference between the real age and the predicted age\n",
    "\n",
    "BA_df = test_df.copy()\n",
    "\n",
    "BA_df['average'] = (BA_df['age_in_years'] + BA_df['pred']) / 2\n",
    "BA_df['difference'] = BA_df['age_in_years'] - BA_df['pred']\n",
    "\n",
    "# Uncoment condition to filter patients with age between 0 and 23 years\n",
    "\n",
    "filtered_BA_df = BA_df#[BA_df['age_in_years'] <= 23]\n",
    "\n",
    "\n",
    "# Calculating the mean and standard deviation of the difference\n",
    "mean_difference = filtered_BA_df['difference'].mean()\n",
    "std_difference = filtered_BA_df['difference'].std()\n",
    "\n",
    "# Creating the Bland-Altman plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(filtered_BA_df['average'], filtered_BA_df['difference'], alpha=0.5)\n",
    "plt.axhline(mean_difference, color='red', linestyle='--')\n",
    "plt.text(filtered_BA_df['average'].max(), mean_difference, 'Mean: {:.2f}'.format(mean_difference), va='center', ha='right', backgroundcolor='w', fontsize=16)\n",
    "plt.axhline(mean_difference + 1.96*std_difference, color='blue', linestyle='--')\n",
    "plt.text(filtered_BA_df['average'].max(), mean_difference + 1.96*std_difference, '+1.96 SD: {:.2f}'.format(mean_difference + 1.96*std_difference), va='center', ha='right', backgroundcolor='w', fontsize=16)\n",
    "plt.axhline(mean_difference - 1.96*std_difference, color='blue', linestyle='--')\n",
    "plt.text(filtered_BA_df['average'].max(), mean_difference - 1.96*std_difference, '-1.96 SD: {:.2f}'.format(mean_difference - 1.96*std_difference), va='center', ha='right', backgroundcolor='w', fontsize=16)\n",
    "\n",
    "plt.xlabel('Average between real age and predicted age', fontsize=16)\n",
    "plt.ylabel('Diference between real age and predicted age', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate the paired t-test for the real ages and the predicted ages\n",
    "t_stat, p_value = stats.ttest_rel(BA_df['age_in_years'], BA_df['pred'])\n",
    "\n",
    "print(f'T-statistic: {t_stat}\\nP-value: {p_value}')\n",
    "## P-Value > 0.05: Fail to reject the null hypothesis (H0) -> The predicted ages are not significantly different from the real ages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with the frequency of each age group in the train set and the MAE and IC of each age group in the test set\n",
    "\n",
    "age_groups = train_df[\"age_group\"].unique()\n",
    "\n",
    "min_age_per_group = {\n",
    "    group: test_df[test_df[\"age_group\"] == group][\"age_in_years\"].min()\n",
    "    for group in age_groups\n",
    "}\n",
    "age_groups_sorted = sorted(age_groups, key=lambda group: min_age_per_group[group])\n",
    "train_df[\"age_group\"].value_counts().sort_index()\n",
    "test_df[\"age_group\"].value_counts().sort_index()\n",
    "mae_per_age_group = test_df.groupby(\"age_group\")[\"abs_error\"].mean().sort_index()\n",
    "std_per_age_group = test_df.groupby(\"age_group\")[\"abs_error\"].std().sort_index()\n",
    "\n",
    "combined_df = pd.DataFrame(\n",
    "    {\n",
    "        \"train_freq\": train_df[\"age_group\"].value_counts().sort_index(),\n",
    "        \"holdout_freq\": test_df[\"age_group\"].value_counts().sort_index(),\n",
    "        \"holdout_mae\": mae_per_age_group,\n",
    "        \"holdout_mae_std\": std_per_age_group,\n",
    "    }\n",
    ")\n",
    "# Drop non-existent age groups in the test set\n",
    "combined_df = combined_df.dropna()\n",
    "combined_df[\"holdout_freq\"] = combined_df[\"holdout_freq\"].astype(int)\n",
    "\n",
    "# Transform age_group into a categorical variable with the correct order\n",
    "combined_df.reset_index(inplace=True)\n",
    "combined_df[\"age_group\"] = pd.Categorical(\n",
    "    combined_df[\"age_group\"], categories=age_groups_sorted, ordered=True\n",
    ")\n",
    "\n",
    "# Order dataframe by age_group\n",
    "combined_df = combined_df.sort_values(\"age_group\")\n",
    "\n",
    "combined_df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting full dataset Error distribution to verify if they are simetrical or if there is a bias\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "ax = sns.distplot(\n",
    "    test_df[\"error\"],\n",
    "    color=\"seagreen\",\n",
    ")\n",
    "\n",
    "plt.xlabel('Error (years)', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.title(\"Error Distribution in Age Prediction\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distributions of the actual ages, predicted ages, prediction errors and absolute prediction errors\n",
    "\n",
    "# Set the style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot the distribution of the actual ages\n",
    "sns.histplot(data=test_df, x='age_in_years', kde=True, color='blue', ax=ax[0, 0])\n",
    "ax[0, 0].set_title('Distribution of Actual Ages', fontsize=14)\n",
    "\n",
    "# Plot the distribution of the predicted ages\n",
    "sns.histplot(data=test_df, x='pred', kde=True, color='orange', ax=ax[0, 1])\n",
    "ax[0, 1].set_title('Distribution of Predicted Ages', fontsize=14)\n",
    "\n",
    "# Plot the distribution of the prediction errors\n",
    "sns.histplot(data=test_df, x='error', kde=True, color='green', ax=ax[1, 0])\n",
    "ax[1, 0].set_title('Distribution of Prediction Errors', fontsize=14)\n",
    "\n",
    "# Plot the distribution of the absolute prediction errors\n",
    "sns.histplot(data=test_df, x='abs_error', kde=True, color='red', ax=ax[1, 1])\n",
    "ax[1, 1].set_title('Distribution of Absolute Prediction Errors', fontsize=14)\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify clusterization of the test set predictions using KMeans with 3 clusters to test if the Human Expert feedback is similar.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Fit a KMeans model with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "test_df['cluster'] = kmeans.fit_predict(test_df[['age_in_years', 'pred']])\n",
    "\n",
    "# Create a scatter plot of actual age vs. predicted age, colored by cluster\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=test_df, x='age_in_years', y='pred', hue='cluster', palette='Set1', alpha=0.6)\n",
    "plt.title('Actual Age vs. Predicted Age, Colored by Cluster', fontsize=14)\n",
    "plt.xlabel('Actual Age', fontsize=12)\n",
    "plt.ylabel('Predicted Age', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the clusterization is similar using log transformation\n",
    "\n",
    "# Apply log transformation\n",
    "test_df['log_age_in_years'] = np.log1p(test_df['age_in_years'])\n",
    "test_df['log_pred_age'] = np.log1p(test_df['pred'])\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "test_df['cluster'] = kmeans.fit_predict(test_df[['log_age_in_years', 'log_pred_age']])\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=test_df, x='log_age_in_years', y='log_pred_age', hue='cluster', palette='Set1', alpha=0.6)\n",
    "plt.title('Log Actual Age vs. Log Predicted Age, Colored by Cluster', fontsize=14)\n",
    "plt.xlabel('Log Actual Age', fontsize=12)\n",
    "plt.ylabel('Log Predicted Age', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if we can find a pattern in the clusterization using a more complex approach (UMAP)\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Load the ResNet50 model with pre-trained weights\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*(list(resnet.children())[:-1]))  # Remove the last layer to get features\n",
    "resnet.eval()\n",
    "\n",
    "# Directory where your images are saved\n",
    "image_dir = 'data/test_set'\n",
    "\n",
    "# Define the image transformations - resize to 224x224 (expected by ResNet), convert to tensor, and normalize\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load and preprocess each image, then use ResNet50 to extract features\n",
    "features = []\n",
    "for img_path in os.listdir(image_dir):\n",
    "    img = Image.open(os.path.join(image_dir, img_path)).convert('RGB')\n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0) \n",
    "\n",
    "    # If you have a GPU, put everything on cuda\n",
    "    input_batch = input_batch.to(DEVICE)\n",
    "    resnet.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = resnet(input_batch)\n",
    "\n",
    "    # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "    features.append(output.cpu().numpy().flatten())\n",
    "\n",
    "# Perform UMAP dimensionality reduction\n",
    "reducer = umap.UMAP(n_epochs=1000, random_state=SEED)\n",
    "embedding = reducer.fit_transform(features)\n",
    "\n",
    "# Append our 2D UMAP components to this DataFrame\n",
    "test_df['UMAP1'] = embedding[:, 0]\n",
    "test_df['UMAP2'] = embedding[:, 1]\n",
    "\n",
    "# Calculate correlation between UMAP components and actual/predicted age\n",
    "correlation_with_umap1 = test_df[['UMAP1', 'age_in_years', 'pred']].corr()\n",
    "correlation_with_umap2 = test_df[['UMAP2', 'age_in_years', 'pred']].corr()\n",
    "\n",
    "print(correlation_with_umap1)\n",
    "print(correlation_with_umap2)\n",
    "\n",
    "# Plot UMAP components with actual age and predicted age\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "sns.scatterplot(data=test_df, x='UMAP1', y='UMAP2', hue='age_in_years', ax=ax[0])\n",
    "ax[0].set_title('UMAP colored by actual age')\n",
    "\n",
    "sns.scatterplot(data=test_df, x='UMAP1', y='UMAP2', hue='pred', ax=ax[1])\n",
    "ax[1].set_title('UMAP colored by predicted age')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the hdbscan clusterization algorithm based on UMAP components\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "# Create an HDBSCAN object\n",
    "clusterer = hdbscan.HDBSCAN(min_samples=10, gen_min_span_tree=True)\n",
    "\n",
    "# Fit the HDBSCAN model\n",
    "clusterer.fit(test_df[['UMAP1', 'UMAP2']])\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "test_df['cluster'] = clusterer.labels_\n",
    "\n",
    "# Plot UMAP components colored by cluster with legend off the grid\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=test_df, x='UMAP1', y='UMAP2', hue='cluster', palette='Spectral', legend=\"full\")\n",
    "plt.title('UMAP colored by HDBSCAN cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual age vs predicted age highlinting the clusters from HDBSCAN\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=test_df, x='age_in_years', y='pred', hue='cluster', palette='Set1', alpha=0.6)\n",
    "plt.title('Actual Age vs. Predicted Age, Colored by Anomaly', fontsize=14)\n",
    "plt.xlabel('Actual Age', fontsize=12)\n",
    "plt.ylabel('Predicted Age', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform anomaly detection using the UMAP components\n",
    "\n",
    "# Anomaly detection: points that are far from the others could be considered anomalies\n",
    "distances = np.sum((embedding - np.mean(embedding, axis=0))**2, axis=1)\n",
    "anomalies = distances > np.percentile(distances, 95)  # Considering the 5% furthest points as anomalies\n",
    "test_df['anomaly'] = anomalies\n",
    "\n",
    "# Plot actual age vs predicted age highlinting the anomalies\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=test_df, x='age_in_years', y='pred', hue='anomaly', palette='Set1', alpha=0.6)\n",
    "plt.title('Actual Age vs. Predicted Age, Colored by Anomaly', fontsize=14)\n",
    "plt.xlabel('Actual Age', fontsize=12)\n",
    "plt.ylabel('Predicted Age', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the sex-specific performance of the model\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot for male\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(test_df[test_df['sex'] == 0]['age_in_years'], bins=20, color='blue', label='Actual Age')\n",
    "sns.histplot(test_df[test_df['sex'] == 0]['pred'], bins=20, color='red', label='Predicted Age')\n",
    "plt.xlabel('Age')\n",
    "plt.title('Distribution of Actual and Predicted Age for Male')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for female\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(test_df[test_df['sex'] == 1]['age_in_years'], bins=20, color='blue', label='Actual Age')\n",
    "sns.histplot(test_df[test_df['sex'] == 1]['pred'], bins=20, color='red', label='Predicted Age')\n",
    "plt.xlabel('Age')\n",
    "plt.title('Distribution of Actual and Predicted Age for Female')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of examples by gender\n",
    "gender_counts = test_df['sex'].value_counts()\n",
    "\n",
    "# Mean predicted age by gender\n",
    "mean_pred_age_by_gender = test_df.groupby('sex')['pred'].mean()\n",
    "\n",
    "# Mean abs_error by gender\n",
    "mean_abs_error_by_gender = test_df.groupby('sex')['abs_error'].mean()\n",
    "\n",
    "# Create figure with two subplots: one for counts and one for mean predicted age\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Bar plot for counts\n",
    "sns.barplot(x=gender_counts.index, y=gender_counts.values, ax=ax[0])\n",
    "ax[0].set_title('Count of Examples by Gender')\n",
    "ax[0].set_xlabel('Gender')\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[0].set_xticklabels(['Male', 'Female'])\n",
    "\n",
    "# Bar plot for mean predicted age\n",
    "sns.barplot(x=mean_pred_age_by_gender.index, y=mean_pred_age_by_gender.values, ax=ax[1])\n",
    "ax[1].set_title('Mean Predicted Age by Gender')\n",
    "ax[1].set_xlabel('Gender')\n",
    "ax[1].set_ylabel('Mean Predicted Age')\n",
    "ax[1].set_xticklabels(['Male', 'Female'])\n",
    "\n",
    "# Bar plot for mean absolute error\n",
    "sns.barplot(x=mean_abs_error_by_gender.index, y=mean_abs_error_by_gender.values, ax=ax[2])\n",
    "ax[2].set_title('Mean Abs Error by Gender')\n",
    "ax[2].set_xlabel('Gender')\n",
    "ax[2].set_ylabel('Mean Abs Error Age')\n",
    "ax[2].set_xticklabels(['Male', 'Female'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scatter plot with the training frequency and the MAE for each age group\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter_plot = sns.scatterplot(\n",
    "    x=\"train_freq\",\n",
    "    y=\"holdout_mae\",\n",
    "    hue=\"age_group\",\n",
    "    data=combined_df,\n",
    "    s=100,\n",
    "    palette='crest',\n",
    "    legend=None,\n",
    ")\n",
    "\n",
    "# Adding the age group as a label for each point\n",
    "for idx, row in combined_df.iterrows():\n",
    "    scatter_plot.text(row[\"train_freq\"], row[\"holdout_mae\"] + 0.3, row[\"age_group\"], horizontalalignment=\"center\", size=\"medium\", color=\"black\")\n",
    "\n",
    "# Calculating the Pearson correlation coefficient\n",
    "pearson_corr = np.corrcoef(combined_df[\"train_freq\"], combined_df[\"holdout_mae\"])[0, 1]\n",
    "\n",
    "# Adding the Pearson correlation coefficient to the plot\n",
    "plt.text(\n",
    "    0.95,\n",
    "    0.95,\n",
    "    f\"Pearson Correlation: {pearson_corr:.2f}\",\n",
    "    ha=\"right\",\n",
    "    va=\"top\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"black\"),\n",
    "    fontsize=14,\n",
    ")\n",
    "\n",
    "# Adding the title and labels\n",
    "plt.xlabel(\"Training Frequency\", fontsize=16)\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\", fontsize=16)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pearsons correlation coefficient between training frequency and MAE for each age group\n",
    "\n",
    "# Define the age groups to calculate the correlation coefficient\n",
    "age_group_0_19 = [\"[0, 5)\", \"[5, 10)\", \"[10, 15)\", \"[15, 20)\"]\n",
    "age_group_20_39 = [\"[20, 25)\", \"[25, 30)\", \"[30, 35)\", \"[35, 40)\"]\n",
    "age_group_40_69 = [\"[40, 45)\", \"[45, 50)\", \"[50, 55)\", \"[55, 60)\", \"[60, 65)\", \"[65, 70)\"]\n",
    "age_groups_70_plus = [\"[70, 75)\",\"[75, 80)\", \"[80, 85)\", \"[85, 90)\", \"[90, 100)\"]\n",
    "\n",
    "# Calculate the correlation coefficient for each age group\n",
    "\n",
    "corr_0_19 = np.corrcoef(combined_df[combined_df[\"age_group\"].isin(age_group_0_19)][\"train_freq\"], combined_df[combined_df[\"age_group\"].isin(age_group_0_19)][\"holdout_mae\"])[0, 1]\n",
    "corr_20_39 = np.corrcoef(combined_df[combined_df[\"age_group\"].isin(age_group_20_39)][\"train_freq\"], combined_df[combined_df[\"age_group\"].isin(age_group_20_39)][\"holdout_mae\"])[0, 1]\n",
    "corr_40_69 = np.corrcoef(combined_df[combined_df[\"age_group\"].isin(age_group_40_69)][\"train_freq\"], combined_df[combined_df[\"age_group\"].isin(age_group_40_69)][\"holdout_mae\"])[0, 1]\n",
    "corr_70_plus = np.corrcoef(combined_df[combined_df[\"age_group\"].isin(age_groups_70_plus)][\"train_freq\"], combined_df[combined_df[\"age_group\"].isin(age_groups_70_plus)][\"holdout_mae\"])[0, 1]\n",
    "\n",
    "# Print the correlation coefficient for each age group\n",
    "\n",
    "print(f\"Correlation coefficient for age group 0-19: {corr_0_19:.2f}\")\n",
    "print(f\"Correlation coefficient for age group 20-39: {corr_20_39:.2f}\")\n",
    "print(f\"Correlation coefficient for age group 40-69: {corr_40_69:.2f}\")\n",
    "print(f\"Correlation coefficient for age group 70+: {corr_70_plus:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the test set by the absolute error and filtering age groups to perform better visualization\n",
    "\n",
    "test_df = test_df.sort_values(by=\"abs_error\", ascending=True)\n",
    "test_df_0_5 = test_df.query(\"age_group == '[0, 5)'\")\n",
    "test_df_5_10 = test_df.query(\"age_group == '[5, 10)'\")\n",
    "test_df_10_15 = test_df.query(\"age_group == '[10, 15)'\")\n",
    "test_df_15_20 = test_df.query(\"age_group == '[15, 20)'\")\n",
    "test_df_20_25 = test_df.query(\"age_group == '[20, 25)'\")\n",
    "test_df_25_30 = test_df.query(\"age_group == '[25, 30)'\")\n",
    "test_df_30_35 = test_df.query(\"age_group == '[30, 35)'\")\n",
    "test_df_35_40 = test_df.query(\"age_group == '[35, 40)'\")\n",
    "test_df_40_45 = test_df.query(\"age_group == '[40, 45)'\")\n",
    "test_df_45_50 = test_df.query(\"age_group == '[45, 50)'\")\n",
    "test_df_50_55 = test_df.query(\"age_group == '[50, 55)'\")\n",
    "test_df_55_60 = test_df.query(\"age_group == '[55, 60)'\")\n",
    "test_df_60_65 = test_df.query(\"age_group == '[60, 65)'\")\n",
    "test_df_65_70 = test_df.query(\"age_group == '[65, 70)'\")\n",
    "test_df_70_75 = test_df.query(\"age_group == '[70, 75)'\")\n",
    "test_df_75_80 = test_df.query(\"age_group == '[75, 80)'\")\n",
    "test_df_80_85 = test_df.query(\"age_group == '[80, 85)'\")\n",
    "test_df_85_90 = test_df.query(\"age_group == '[85, 90)'\")\n",
    "test_df_90_100 = test_df.query(\"age_group == '[90, 100)'\")\n",
    "\n",
    "test_df.head(10).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing important regions of the images for predictions\n",
    "\n",
    "img_iloc = 3 # Select image from the sorted test set (-1 = worst prediction, 0 = best prediction)\n",
    "\n",
    "ig_df = test_df\n",
    "image_path = ig_df.iloc[img_iloc][\"path\"]\n",
    "image_id = ig_df.iloc[img_iloc][\"id\"]\n",
    "label = ig_df.iloc[img_iloc][\"age_in_years\"]\n",
    "\n",
    "input_size = (299, 299) # Input size of the model, for InceptionV4 is (299, 299)\n",
    "output_size = (720, 1475) # If none, the output size will be the same as the input size\n",
    "\n",
    "visualize_integrated_gradients_age(image_path, image_id, label, model, input_size, device=DEVICE, output_size=None)\n",
    "# visualize_gradient_shap(image_path, label, model, input_size, device=DEVICE, output_size=None)\n",
    "# visualize_saliency(image_path, label, model, input_size, device=DEVICE, output_size=None)\n",
    "# visualize_captum_methods(image_path, label, model, input_size, device=DEVICE, output_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all image results in a folder\n",
    "\n",
    "input_size = (299, 299)  # Input size of the model, for InceptionV4 is (299, 299)\n",
    "output_size = None  # If none, the output size will be the same as the input size\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    image_path = row[\"path\"]\n",
    "    image_id = row[\"id\"]\n",
    "    label = row[\"age_in_years\"]\n",
    "\n",
    "    visualize_integrated_gradients_age(\n",
    "        image_path,\n",
    "        image_id,\n",
    "        label,\n",
    "        model,\n",
    "        input_size,\n",
    "        device=DEVICE,\n",
    "        output_size=output_size,\n",
    "        save=True,\n",
    "        save_path=\"data/age_results/\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test_df with predictions and absolute error on csv file\n",
    "\n",
    "test_df.to_csv(\"data/age_results/test_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
